{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/input'\n",
    "\n",
    "import helper\n",
    "\n",
    "helper.download_extract('celeba', data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import problem_unittests as tests\n",
    "\n",
    "def model_inputs(image_width, image_height, image_channels, z_dim):\n",
    "\n",
    "    real_input_images = tf.placeholder(tf.float32, [None, image_width, image_height, image_channels], 'real_input_images')\n",
    "    input_z = tf.placeholder(tf.float32, [None, z_dim], 'input_z')\n",
    "    learning_rate = tf.placeholder(tf.float32, [], 'learning_rate')\n",
    "    return real_input_images, input_z, learning_rate\n",
    "\n",
    "tests.test_model_inputs(model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(images, reuse=False, alpha=0.2, keep_prob=0.5):\n",
    "\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # Entrada 28x28xn\n",
    "        # 14x14x64\n",
    "        conv1 = tf.layers.conv2d(images, 64, 5, 2, padding='same', kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        lrelu1 = tf.maximum(alpha * conv1, conv1)\n",
    "        drop1 = tf.layers.dropout(lrelu1, keep_prob)\n",
    "        \n",
    "        # 7x7x128\n",
    "        conv2 = tf.layers.conv2d(drop1, 128, 5, 2, 'same', use_bias=False)\n",
    "        bn2 = tf.layers.batch_normalization(conv2)\n",
    "        lrelu2 = tf.maximum(alpha * bn2, bn2)\n",
    "        drop2 = tf.layers.dropout(lrelu2, keep_prob)\n",
    "        \n",
    "        # 4x4x256\n",
    "        conv3 = tf.layers.conv2d(drop2, 256, 5, 2, 'same', use_bias=False)\n",
    "        bn3 = tf.layers.batch_normalization(conv3)\n",
    "        lrelu3 = tf.maximum(alpha * bn3, bn3)\n",
    "        drop3 = tf.layers.dropout(lrelu3, keep_prob)\n",
    "        \n",
    "        flat = tf.reshape(drop3, (-1, 4*4*256))\n",
    "        logits = tf.layers.dense(flat, 1)\n",
    "        out = tf.sigmoid(logits)\n",
    "        \n",
    "        return out, logits\n",
    "\n",
    "\n",
    "tests.test_discriminator(discriminator, tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, out_channel_dim, is_train=True, alpha=0.2, keep_prob=0.5):\n",
    "\n",
    "    with tf.variable_scope('generator', reuse=(not is_train)):\n",
    "        # 4x4x1024\n",
    "        fc = tf.layers.dense(z, 4*4*1024, use_bias=False)\n",
    "        fc = tf.reshape(fc, (-1, 4, 4, 1024))\n",
    "        bn0 = tf.layers.batch_normalization(fc, training=is_train)\n",
    "        lrelu0 = tf.maximum(alpha * bn0, bn0)\n",
    "        drop0 = tf.layers.dropout(lrelu0, keep_prob, training=is_train)\n",
    "        \n",
    "        # 7x7x512\n",
    "        conv1 = tf.layers.conv2d_transpose(drop0, 512, 4, 1, 'valid', use_bias=False)\n",
    "        bn1 = tf.layers.batch_normalization(conv1, training=is_train)\n",
    "        lrelu1 = tf.maximum(alpha * bn1, bn1)\n",
    "        drop1 = tf.layers.dropout(lrelu1, keep_prob, training=is_train)\n",
    "        \n",
    "        # 14x14x256\n",
    "        conv2 = tf.layers.conv2d_transpose(drop1, 256, 5, 2, 'same', use_bias=False)\n",
    "        bn2 = tf.layers.batch_normalization(conv2, training=is_train)\n",
    "        lrelu2 = tf.maximum(alpha * bn2, bn2)\n",
    "        drop2 = tf.layers.dropout(lrelu2, keep_prob, training=is_train)\n",
    "        \n",
    "        # Sa√≠da: 28x28xn\n",
    "        logits = tf.layers.conv2d_transpose(drop2, out_channel_dim, 5, 2, 'same')\n",
    "        \n",
    "        out = tf.tanh(logits)\n",
    "        \n",
    "        return out\n",
    "\n",
    "tests.test_generator(generator, tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(input_real, input_z, out_channel_dim, alpha=0.2, smooth_factor=0.1):\n",
    "\n",
    "    d_model_real, d_logits_real = discriminator(input_real, alpha=alpha)\n",
    "    \n",
    "    d_loss_real = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real,\n",
    "                                                labels=tf.ones_like(d_model_real) * (1 - smooth_factor)))\n",
    "    \n",
    "    input_fake = generator(input_z, out_channel_dim, alpha=alpha)\n",
    "    d_model_fake, d_logits_fake = discriminator(input_fake, reuse=True, alpha=alpha)\n",
    "    \n",
    "    d_loss_fake = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.zeros_like(d_model_fake)))\n",
    "    \n",
    "    g_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.ones_like(d_model_fake)))\n",
    "\n",
    "    return d_loss_real + d_loss_fake, g_loss\n",
    "\n",
    "\n",
    "tests.test_model_loss(model_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(d_loss, g_loss, learning_rate, beta1):\n",
    "\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        d_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "        g_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(g_loss, var_list=g_vars)\n",
    "\n",
    "    return d_train_opt, g_train_opt\n",
    "\n",
    "\n",
    "tests.test_model_opt(model_opt, tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def show_generator_output(sess, n_images, input_z, out_channel_dim, image_mode):\n",
    "\n",
    "    cmap = None if image_mode == 'RGB' else 'gray'\n",
    "    z_dim = input_z.get_shape().as_list()[-1]\n",
    "    example_z = np.random.uniform(-1, 1, size=[n_images, z_dim])\n",
    "\n",
    "    samples = sess.run(\n",
    "        generator(input_z, out_channel_dim, False),\n",
    "        feed_dict={input_z: example_z})\n",
    "\n",
    "    images_grid = helper.images_square_grid(samples, image_mode)\n",
    "\n",
    "    return images_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch_count, batch_size, z_dim, learning_rate, beta1, get_batches, data_shape, data_image_mode,\n",
    "          print_every=10, show_every=100):\n",
    "\n",
    "    input_real, input_z, _ = model_inputs(data_shape[1], data_shape[2], data_shape[3], z_dim)\n",
    "    d_loss, g_loss = model_loss(input_real, input_z, data_shape[3], alpha=0.2)\n",
    "    d_train_opt, g_train_opt = model_opt(d_loss, g_loss, learning_rate, beta1)\n",
    "    \n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    sample_z = np.random.uniform(-1, 1, size=(72, z_dim))\n",
    "    \n",
    "    samples, losses = [], []\n",
    "    \n",
    "    steps = 0\n",
    "    count = 0\n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "         \n",
    "        save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "        ckpt = tf.train.latest_checkpoint('./model/')\n",
    "        saver.restore(sess, save_path)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "        os.mkdir('output')\n",
    "        for epoch_i in range(epoch_count):\n",
    "            os.mkdir('output/'+ str(epoch_i))\n",
    "            for batch_images in get_batches(batch_size):\n",
    "\n",
    "                steps += 1\n",
    "                batch_images *= 2.0\n",
    "                \n",
    "                batch_z = np.random.uniform(-1, 1, size=(batch_size, z_dim))\n",
    "                \n",
    "                sess.run(d_train_opt, feed_dict={input_real: batch_images, input_z: batch_z})\n",
    "                sess.run(g_train_opt, feed_dict={input_z: batch_z})\n",
    "                \n",
    "                if steps % print_every == 0:\n",
    "                    train_loss_d = d_loss.eval({input_real: batch_images, input_z: batch_z})\n",
    "                    train_loss_g = g_loss.eval({input_z: batch_z})\n",
    "                    print(\"Epoch {}/{} Step {}...\".format(epoch_i+1, epoch_count, steps),\n",
    "                      \"Discriminator Loss: {:.4f}...\".format(train_loss_d),\n",
    "                      \"Generator Loss: {:.4f}\".format(train_loss_g))\n",
    "                     \n",
    "\n",
    "                if steps % show_every == 0:\n",
    "                    count = count +1\n",
    "                    iterr = count*show_every\n",
    "                    \n",
    "                    images_grid = show_generator_output(sess, 25, input_z, data_shape[3], data_image_mode)\n",
    "                    dst = os.path.join(\"output\", str(epoch_i), str(iterr)+\".png\")\n",
    "                    images_grid.save(dst)\n",
    "                           \n",
    "                if epoch_i % 10 == 0:\n",
    "                    if not os.path.exists('./model/'):\n",
    "                        os.makedirs('./model')\n",
    "                    saver.save(sess, './model/' + str(epoch_i))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "arquivo = open('HoraInicio.txt', 'w')\n",
    "tempoInicial = \"Hora inicial: \" + datetime.today().strftime('%d/%m/%Y %H:%M:%S')\n",
    "arquivo.write(str(tempoInicial))\n",
    "arquivo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "z_dim = 100\n",
    "learning_rate = 0.00025\n",
    "beta1 = 0.45\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "celeba_dataset = helper.Dataset('celeba', glob(os.path.join(data_dir, 'img_align_celeba/*.jpg')))\n",
    "with tf.Graph().as_default():\n",
    "    train(epochs, batch_size, z_dim, learning_rate, beta1, celeba_dataset.get_batches,\n",
    "          celeba_dataset.shape, celeba_dataset.image_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = open('HoraFinal.txt', 'w')\n",
    "tempoFinal = \"Hora final: \" + datetime.today().strftime('%d/%m/%Y %H:%M:%S') + \" - Epocas: \"+ str(epochs)\n",
    "arquivo.write(str(tempoFinal))\n",
    "arquivo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
